---
title: "[자연어 처리] 머신 러닝 - 2"
author: <author_id>
date: 2024-02-25 18:00:00 +09:00
categories: [NLP, Machine Learning]
math: true
tag: [자연어처리, 머신 러닝, NLP, Machine Learning, 가설, 가중치, 편향, 손실 함수, 비용 함수, 목적함수, 옵티마이저, 최적화 알고리즘]
toc: true
---

> 이 포스트는 [**딥 러닝을 이용한 자연어 처리 입문**](https://wikidocs.net/book/2155)을 읽고 공부 겸 정리한 글입니다.

[**머신러닝 - 1**](https://53min.github.io/posts/NLP-Machine_Learning1/)을 읽고 오시면 더욱 도움이 됩니다.

## 연결고리

이 내용은 넓은 개념과 정확한 이론 사이에 간극을 채우기 위한 주관적인 내용이다.
이전 포스트를 읽었다면 대충 머신러닝에 대한 느낌이 잡혔을 거라 생각한다. 하지만 이 포스트에서는 머신러닝 기법들의 개념에 대해 다룰건데, 필자는 '기계가 목적에 맞게 준비한 데이터를 학습하여 규칙성이나 특징을 발견하고 새로운 데이터가 주어졌을 때 적절한 결과를 도출한다'라는 숲같은 개념에서 갑자기 바로 나뭇잎을 배우는 느낌이 들었다. 따라서 중간 단계의 이해를 스스로 정의해보려고 한다. 

내가 가고 싶은 목적지가 있다고 하자. 이 목적지까지 가는 방법으로는 자동차, 자전거, 비행기, 걷기 등 여러가지가 있다. 머신러닝이란 이러한 이동수단 중에 하나라고 생각한다. 그리고 개인적으로 필자는 머신러닝이 이동수단 중에 자동차 정도라고 느꼈으므로, 내가 자동차를 통해 목적지를 가기로 결정했다고 해보자. 보통은 네비게이션으로 목적지를 설정하고 출발할텐데, 목적지를 설정하는 과정에서 많은 옵션들이 있다. 최소 시간 우선, 고속도로 우선, 국도 우선, 무료도로 우선 등이 있는데 이러한 옵션들이 머신러닝 기법에 해당한다고 생각한다. 무료도로 우선을 선택한다면 비용은 확실히 절감되는 반면에 소요 시간이 늘어날 것이고, 최소 시간 우선을 선택하면 소요 시간은 된축되더라도 어느정도 비용이 소모될 것이다. 결국 모든 선택지가 장단점이 있기에 주어진 상황과 목적에 따라 손해를 최소화하고, 이익을 극대화하는 선택지를 고르는 것이다. 이 내용은 머신러닝을 넘어 프로그래밍 전반에 적용된다고 느낀다.

이 다음은 머신러닝에서 자주 쓰이며, 기법들을 다루기 전에 미리 알고 가면 좋은 개념들이다.

### 가설(Hypothesis)

수학적 용어지만 머신 러닝에서는 살짝 다르다. 가설이 곧 내가 사용할 기법을 의미한다고 볼 수 있으며, 내가 가진 목적을 전제로 가장 데이터들 사이의 관계를 잘 표현할 수 있는 함수 또는 식이다. 지도학습에서는 영향을 주는 독립변수와 영향을 받는 종속 변수의 관계로 표현되어, 독립변수를 x, 종속 변수를 y로 설정하며 y = ~ 형태로 표현된다. 비지도학습의 경우에는 종속변수 없이 독립변수들 사이에 관계가 식으로 표현되기도 한다. 각 기법마다 데이터 사이의 관계가 다르게 표현되어 내 목적에 맞는 가설을 설정해야한다.

### 가중치(Weight)와 편향(Bias)

위에서 가설이 잘 설정되었다고 하였다. 가중치와 편향이란 이 관계를 직접적으로 표현해주는 매개변수 이다. 가중치는 w, 편향은 b라고 표현하며, 만약 지도학습에서 x와 y가 직선 관계라면, y = wx + b라고 표현한다. 가중치는 독립변수인 x에 곱해져 직접적으로 영향을 주고, 편향은 가중치와 곱해진 독립변수와 종속변수 사이를 보정해준다고 생각하면 된다. 이전 포스트에서 머신러닝의 학습 방법을 설명하였다. 가중치와 편향은 모델이 학습하면서 오차를 줄이고 정확도를 높이는 방향으로 점차 변한다.

### 손실함수(Loss Function)

위의 개념을 통해 데이터 사이의 관계가 w와 b를 통해 표현된다는 것을 알았고, w와 b가 학습을 통해 점점 최적화된다는 것을 알게되었다. 그렇다면 결국 학습의 목적은 적절한 w와 b를 찾아가는 것이다. 준비한 데이터를 통해 실제값이 있을 것이고, 가설에 데이터를 대입하여 예측값을 얻을 수 있다. 손실함수란 실제값과 예측값의 오차를 계산하는 식을 표현한 것이다. 또한 단순히 오차를 계산하는 것에 그치지 않고 오차를 줄이는 작업에 최적화 된 식이여야만 한다. 비용함수(Cost function)라고 부르기도 하며, 함수의 값을 최소화 또는 최대화하는 목적을 가진 함수를 뜻하는 목적함수(Objective function)라고 하기도 한다.

### 최적화 알고리즘(Optimizer, 옵티마이저)

위에서 손실함수란 예측값과 실제값 사이의 오차를 줄이는 작업에 최적화 된 식이라고 정의하였다. 이러한 오차를 최소화하는 작업을 수행하고 결국 오차를 최소화하는 매개변수인 w와 b를 찾는 일을 해야하는데 이러한 작업에 사용되는 알고리즘을 옵티마이저(Optimizer) 또는 최적화 알고리즘이라고 부른다. 결국 머신러닝에서 훈련 또는 학습은 옵티마이저를 통해 적절한 w와 b를 찾아가는 것을 이야기 한다.

위의 개념들을 통해 머신러닝을 정의해보려고 한다.

머신러닝이란 목적에 맞게 내가 준비한 데이터들 사이의 관계를 가장 잘 표현하는 가설을 설정하고, 가설과 목적에 맞는 손실함수와 옵티마이저를 정한다. 이후 데이터를 통해 손실함수로 오차를 계산하고 옵티마이저를 통해 오차를 줄이는 쪽으로 가중치와 편향을 업데이트하는 것을 반복한다. 이후에 새로운 데이터를 모델에 입력하고 출력된 결과를 평가하는 것이다.

개념위주로 글을 작성하여 기법들과 함께 예시를 들으려고 했으나, 내용이 길어져 이 개념을 적용한 머신러닝 기법들은 다음 포스트에서 다루려고 한다.