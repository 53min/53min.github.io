---
title: "[자연어 처리] 언어 모델"
author: nimgnas
date: 2024-02-05 18:00:00 +09:00
categories: [NLP, Language Model]
math: true
tag: [자연어처리, 언어 모델, NLP, Language Model, 통계적 언어 모델, SLM, Statistical Language Model, N-gram, 펄플렉서티, Perplexity]
---

> 이 포스트는 [**딥 러닝을 이용한 자연어 처리 입문**](https://wikidocs.net/book/2155)을 읽고 공부 겸 정리한 글입니다. 언어는 python입니다.

## 언어 모델

**언어 모델(Language Model)**이란 문장에 어떤 확률을 매기는 모델이다. 문장에 할당된 확률에 따라 기계는 이 문장이 적절한 문장인지, 아닌지를 판단하게 된다. 다른 설명으로는, 단어가 주어졌을 때 다음에 어떤 단어가 와야 적절한 지 판단한다. 언어 모델은 통계적 언어 모델과 인공신경망 언어 모델이 존재하는데 현재는 성능이 뛰어난 인공신경망 기반 모델을 주로 사용한다. 하지만 통계학 기반의 언어 모델은 인공신경망 기반의 언어 모델을 이해하는데 도움이 되므로 이 포스트에서는 통계적 언어 모델에 대해 다루려고 한다.

언어 모델이 문장(단어 시퀀스)에 확률을 할당하는 주된 방법은 이전 단어들을 보고 다음 단어를 예측하게 하는 것이다. 이러한 작업을 **언어 모델링(Language Modeling)**이라고 한다. 언어 모델링의 다른 방법으로는 양쪽 단어를 보고 가운데 단어를 예측하는 방법도 있다.

## 통계적 언어 모델

**통계적 언어 모델(Statistical Language Model, SLM)**은 가장 전통적인 언어 모델이다. 이 모델의 모델링을 이해하려면 통계적인 지식이 필요하다.

> P(B \| A) = P(A, B)P(A) -> P(A, B) = P(A)P(B \| A) 이 식은 조건부 확률의 연쇄 법칙이다.

> 위 식을 확장하면 P(X1, X2,..., Xn) = P(X1)P(X2 \| X1)...P(Xn \| X1,..., Xn-1)이다.

문장은 단어가 구성하고 있다. 따라서 문장안에 단어들은 문맥이라는 관계로 서로 영향을 주고 받는다. 그렇게 때문에 문장 내의 단어는 앞에 단어의 영향을 받을 수 밖에 없어 조건부 확률은 문장에 적용하기에 적합한 개념이다. SLM에서 문장의 확률은 각 단어의 예측 확률의 곱이다. 아래는 조건부 확률을 문장에 적용한 예시이다.

> P(I love you) = P(I)P(love \| I)P(you \| I love)

그렇다면 각 단어의 예측 확률은 어떻게 구할까?

> P(you\|I love) = count(I love you) / count(I love)

위의 식에서 count는 말그대로 카운트이다. 학습한 코퍼스 데이터에서 I love가 나온 경우가 10번이고, I love 뒤에 you가 나온 경우가 7번이라면 P(you \| I love)는 0.7이다. 이러한 접근법을 **카운트 기반 접근**이라고 한다.

카운트 기반 접근의 한계로는 **희소문제**가 있다. 우리 일상 생활에서는 I love뒤에 you라는 단어가 나올 확률이 분명하게 존재한다. 하지만 만약에 언어 모델 학습 시, 코퍼스 내에  I love you라는 문장이 존재하지 않는다면 이 단어에 대한 확률은 0이 되고, 만약 I love라는 단어 시퀀스가 없다면 분모가 0이 되어 확률이 정의되지 않는다. 그렇다면 I love you라는 문장이 현실에서 쓰이지 않는가? 아니다. 이처럼 현실에서는 충분히 가능한 문장이지만 데이터의 부족으로 정확하게 모델링이 되지 않는 문제를 **희소문제**라고 한다.

희소문제를 완화하는 방법이 다양하게 존재하지만 근본적인 해결책이 되지 못해 결국 언어 모델의 트렌드가 인공신경망 언어 모델로 넘어가게 된다.

## N-gram 언어 모델

N-gram 언어 모델은 카운트 기반 접근을 사용하는 SLM의 한 종류이다. 하지만 앞서 공부한 모델과의 차이점은 뒤에 오는 단어를 예측할 때 앞에서 단어를 고려하는 개수이다. 앞의 모델은 모든 단어를 고려했지만 N-gram 모델은 N개의 단어만 고려한다.

위에서 공부한 SLM의 한계는 준비한 코퍼스에서 필요한 문장이나 단어가 존재하지 않을 수도 있다는 점이다. 계산이 필요한 문장이 길어질수록 코퍼스에 존재하지 않을 확률이 더 높아지게 되어 한계가 더욱 명확해진다. 하지만 N-gram을 이용하여 임의의 개수만 고려하여 단어를 카운트하기에 해당 단어가 코퍼스 내에 존재할 확률이 더욱 높아진다.

N-gram에서는 연속적인 N개의 단어를 하나의 토큰으로 인식한다. n이 1일 때는 unigram, 2일 때는 bigram, 3일 때는 trigram, 4이상부터는 그대로 n-gram이라고 부르기도한다.

예를 들어, I love you so much가 있을 때, 각 n에 대해서 n-gram을 구해보겠다.
- unigram: I, love, you, so, much
- bigram: I love, love you, you so, so much
- trigram: I love you, love you so, you so much
- 4-gram: I love you so, love you so much

> 만약 bigram에서 I love you so 다음에 나올 단어를 예측하고 싶다면, P(w \| you so) = count(you so w) / count(you so) 이다. 그리고 코퍼스 내에서 you so가 100번 등장하고 you so bad가 50번, you so much가 20번 등장했다고 하자. 그러면 you so 다음에 bad이 등장할 확률은 0.5이고, much가 등장할 확률은 0.2라서 우리는 확률적으로 bad이 더 적합하다고 판단한다.

이것만 보면 N-gram이 앞서 나온 SLM의 단점을 보완한 상위모델이라고 볼 수 있다. 어느정도는 맞겠지만 단점 역시 존재한다. 위의 예시에서 I love라는 주어, 동사를 반영하지 않았다. 하지만 만약에 trigram에서 love라는 동사를 반영했더라면 같은 결과가 나왔을까? 물론 어떤 코퍼스냐에 따라 같은 결과가 나올 수도 있다. 다만 이 부분이 시사하는 바는 전체를 고려하는 것이 아니라 부분만 보기에 문장이 자연스럽지 않게 될수도 있다는 점이다.

그렇다면 N을 크게 하면 되지 않을까? 이것 역시도 무조건 맞는 선택은 아니다 N이 커질수록 결국 SLM과 비슷해지기 때문에 희소 문제가 두드러질 것으로 예측된다. 그렇다면 N에 대한 선택은 저울이라고 볼 수 있다. N이 커지면 토큰 사이즈가 커져 모델 사이즈가 커지고 희소문제가 심각해지고, N이 작다면 문장 근사의 정확도가 감소할 것이다. 이러한 trade-off 문제를 고려하여 N은 최대 5가 넘지 않길 권장한다고 한다.

이러한 문제들을 듣다보면 이러한 생각이 들기도 한다. 그렇다면 코퍼스를 완벽하게 준비하면 되는게 아닐까? 이 말은 정답인 거 같다. 하지만 그렇다고 전세계의 모든 문장을 학습할 수는 없는 노릇이다. 하지만 언어 모델의 성능은 코퍼스가 좌우하기에 모델이 사용될 분야에 맞는 코퍼스를 수집하여 모델을 학습하는 것이 성능이 좋은 모델을 제작할 확률이 높다.

## 펄플렉서티

모델을 구축했다면 그 다음은 성능 평가일 것이다. 모델의 성능은 모델이 주어진 업무를 얼마나 잘 처리하는 지 알 수 있는 지표이다. 그렇다면 성능은 어떻게 평가할 수 있을까? 당연히 업무를 시켜보면 알 수 있다. 다만 여러 모델을 평가할 때 일일히 실제 업무를 시키고 정확도를 비교하는 작업은 비효율적이다. 따라서 정확성은 조금 떨어질 수 있지만 모델 내의 테스트 데이터를 계산하여 간단하게 성능을 평가하는 방법이 **펄플렉서티(perplexity)**이다.

펄플렉서티는 줄여서 PPL이라고 하고, 'perplexed'는 '헷갈리는'과 유사한 뜻을 가지고 있다고 한다. 따라서 PPL은 헷갈리는 정도라고 할 수 있다. 결국 PPL이 높다면 많이 헷갈린단 뜻이고, 낮다면 적게 헷갈린다는 것이고, 이는 즉슨 PPL이 낮을수록 성능이 좋다는 것을 의미한다.

PPL은 문장 확률에 역수를 취하고 문장길이 만큼의 제곱근이다.

$$ PPL(W) = P(w1, w2,...,wn)^{-1/N} = \sqrt[n]{1 \over P(w1, w2,...,wn)} $$

위의 예시는 SLM의 단어 시퀀스 확률 기준이고, N-gram이라면 N-gram의 단어 시퀀스 확률식을 적용하면 된다.

PPL은 선택할 수 있는 경우의 수를 의미하는 분기계수이다. 따라서 PPL은 언어 모델이 특정 시점에서 몇 가지 선택지를 고민하고 있는 지를 의미한다. 어떤 테스트 데이터에 대하 PPL값이 10이 나왔다면 해당 테스트 데이터에 대해 다음 단어를 예측하는 모든 시점에서 평균 10개의 단어 중에 어떤 단어를 선택할 지 고민한다고 보면 된다. 따라서 모델 성능을 비교할 때, 같은 테스트 데이터에 대하여 PPL값이 더 낮은 모델이 성능이 좋다고 볼 수 있다.

단, PPL값이 낮다는 것은 테스트 데이터에 대하여 정확도가 높다는 것이, 사람이 직접 느끼기에 좋은 언어 모델이라는 것을 의미하는 것은 아니다. 또한 테스트 데이터에 의존하므로 충분한 양과 적절한 분야(도메인)의 테스트 데이터를 사용해야 신뢰도가 높다.

## 한국어 언어 모델

영어나 다른 언어에 비해서 한국어는 다음과 같은 이유로 언어 모델을 이용하여 단어를 예측하는 것이 훨씬 어렵다.

### 1. 어순이 중요하지 않다.
> 나는 체육관에서 운동을 한다. / 나는 운동을 체육관에서 한다. / 체육관에서 나는 운동을 한다.

이와 같이 한국어는 어순이 달라도 의미가 일맥상통하는 것을 볼 수 있다. 따라서 다음 단어가 어떤 것이 등장해도 어색하지 않아 다음 단어를 예측하는 것이 더욱 어렵다.

### 2. 교착어이다.
한국어에는 영어에서는 존재하지 않는 조사라는 품사가 있다. 이는 주어나 목적어에 붙어서 문장을 자연스럽게 만들어주는 역할을 한다.
> 그가, 그는, 그의, 그에게

이렇게 한 단어가 여러 모양이 될 수 있어 한국에서는 토큰화를 통해 접사나 조사를 분리해주는 작업이 중요하다.

### 3. 띄어쓰기가 제대로 지켜지지 않는다.
한국어에서는 띄어쓰기가 지켜지지 않아도 문장을 이해하는 데에 문제가 되지 않으며, 띄어쓰기 규칙 또한 까다로운 편에 속한다. 따라서 한국어 코퍼스에서 띄어쓰기가 제대로 지켜지지 않은 경우가 많은데, 이런 경우 토큰이 제대로 분리되지 않아 모델 성능에 악영향을 끼칠 수 있다.




지금까지 언어모델의 몇가지 종류와 특징에 대해 공부해보았다. 더 발달한 모델이 많지만 이전 모델에서 단점을 보완한 모델이라는 생각이 들어 이전 모델들에 대한 이해도를 높이는 것이 최근 모델에 대해 도움이 될 거 같다고 생각한다.