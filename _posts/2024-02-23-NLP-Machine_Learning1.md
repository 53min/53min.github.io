---
title: "[자연어 처리] 머신 러닝 - 1"
author: <author_id>
date: 2024-02-23 18:00:00 +09:00
categories: [NLP, Machine Learning]
math: true
tag: [자연어처리, 머신 러닝, NLP, Machine Learning, Linear Regression, Logistic Regression, Softmax Regression, 선형 회귀, 로지스틱, 소프트맥스]
toc: true
---

> 이 포스트는 [**딥 러닝을 이용한 자연어 처리 입문**](https://wikidocs.net/book/2155)을 읽고 공부 겸 정리한 글입니다. 언어는 python입니다.

## **머신 러닝**

**_머신러닝_**이란 기존의 프로그래밍 접근 방식에서 한계를 보완하기 위한 새로운 접근 방식이다. 예를 들어, 사진을 주고 이 사진이 강아지인지 고양이인지 구분한다고 하자. 사진을 보고 구분하는 것은 사람에게는 쉬운 일이다. 하지만 이 문제를 프로그램으로 구현할려고 하면 쉽지 않을 것이다. 사진이란 통일된 양식이 아니라 모두 다르기에 모든 사진에 적용하는 알고리즘을 작성하는 것은 불가능할 것이다.

그렇다면 사람은 어떻게 쉽게 구분할 수 있을까? 우리들은 이미 수많은 고양이와 강아지를 보고 무엇이 강아지인지 무엇이 고양이인지 배웠기 때문이다. 새로운 동물을 보았을 때, 이전에 경험한 수많은 강아지와 고양이를 떠올린 후 각각의 특징을 비교하여 판단하기 때문에 쉽게 구분이 가능하다. 

**머신러닝**은 이러한 사람의 방식을 기계에 적용한 것이다. 기계에게 사진과 이 사진이 어떤 동물인지를 묶어서 충분한 양의 데이터와 해답을 전달하면 기계가 스스로 규칙성을 발견할 것이다. 데이터가 주어지고 기계가 규칙성을 찾는 과정을 **훈련** 또는 **학습**이라고 한다.

기계가 학습을 하면서 발견한 규칙성을 토대로 새로운 사진을 보았을 때 적절한 해답을 제시할 것이다. 이러한 접근법은 기존의 프로그래밍 방식으로는 해결하기 어려웠던 문제들의 해결책이 되기도 한다.

### 데이터의 분리

위의 개념에서 알 수 있듯이 머신러닝에서 데이터는 아주 중요한 역할이다. 머신 러닝을 위한 데이터를 충분히 수집했다면 보통 그 데이터를 분리하여 사용한다. 머신러닝의 목적은 데이터를 이용해 학습시킨 후 새로운 데이터가 주어졌을 때 그 데이터에 대한 적절한 해답을 주는 것이다. 그래서 준비한 데이터를 각각 훈련, 검증, 테스트 데이터로 분리한다.

> 쉽게 말해서 훈련 데이터는 문제집, 검증 데이터는 모의고사, 테스트 데이터는 수능이라고 생각하면 편하다.

훈련데이터에 대해서는 성능이 좋지만 테스트 데이터에 대한 성능이 떨어지는 것을 **과적합(overfitting)**이라고 하는데 검증 데이터는 과적합 판단과 하이퍼 파라미터의 조정을 통한 정확도 향상을 위한 것이고 테스트 데이터는 모델의 최종 성능을 평가하는 것이다.

 **하이퍼 파라미터(초매개변수)**란 모델 성능에 영향을 주는 변수로 사람이 직접 지정하는 값이다. 반면 가중치와 편향같이 모델이 학습하면서 계속 변화하는 변수를 **매개변수**라고 한다. 또한 하이퍼 파라미터를 조정하는 것을 **튜닝(tuning)**한다고 부른다.

또한 한 데이터에서 독립변수들을 특성(Feature)이라고 하고 여러개의 데이터에서 한 데이터를 샘플(Sample)이라고 한다. 행렬 관점으로 보면 행을 샘플 열을 특성이라고 할 수 있다.

### 머신러닝이 적용되는 문제

머신러닝이 적용되는 문제는 대부분 분류 또는 회귀이다. 회귀 문제는 연속적인 수의 범위 내에서 예측값을 계산하는 것을 말하고 분류 문제는 여러 개의 선택지 중 가장 적절한 선택을 하는 걸 말한다. 분류 문제 중에서도 두가지 선택지가 주어진 경우를 **이진 분류 문제(binary Classification)**, 세 개 이상의 선택지가 주어진 경우를 **다중 클래스 분류(Multi-class Classification)**라고 한다.

> 회귀 문제의 예시로는 주가의 예측, 분류 문제의 예시로는 정상 메일, 스팸 메일 판단이 있다.

### 학습 방법

머신 러닝의 학습 방법은 크게 지도 학습, 비지도 학습, 강화 학습으로 나뉜다.

**지도학습(Supervised Learning)**이란 데이터에 정답이 포함되어 학습하는 것이다. 대부분의 자연어처리는 지도학습에 속하고 데이터의 정답을 레이블(Label)이라고 부른다.

**비지도학습(Unsupervised Learning)**이란 데이터에 레이블이 없이 학습하는 것이다. 여러개의 데이터가 있고 비슷한 데이터끼리 군집을 형성시키려고 할 때 비지도 학습을 이용하기도 한다.

**강화학습(Reinforcement Learning)**이란 시행착오를 통해 실수를 줄이고 보상을 최대화하는 방법으로 학습하는 방식이다.

**자기지도 학습(Self-Supervised Learning, SSL)**이란 큰 갈래의 학습 방법은 아니지만 레이블이 없는 데이터가 주어졌을 때, 모델이 학습을 위해 스스로 레이블을 만들어서 학습하는 방법이다.

### 혼동 행렬(Confusion Matrix)

**혼동 행렬**이란 단순히 전체 문제 수에서 맞춘 문제 수의 비율인 정확도의 개념에서 맞춘 결과에 틀린 결과에 대한 정보를 더한 확장된 개념이다. 혼동 행렬의 각 열은 예측값이고, 각 행을 실제 값을 나타낸다. 참과 거짓을 예측하는 문제라고 하면 혼동 행렬은 아래와 같다.

|          | 예측 참 | 예측 거짓 |
|:---------|:--------|:---------|
| 실제 참   | TP     | FN       |
| 실제 거짓 | FP     | TN       |

다음은 머신 러닝에서 정의하는 TP, FP, FN, TN이다. 이 개념을 이용하여 정밀도(Precision),  재현율(Recall)과 정확도(Accuracy)를 계산한다.

- True Positive(TP): 실제 True인 정답을 True라고 예측(정답)
- False Positive(FP): 실제 False인 정답을 True라고 예측(오답)
- False Negative(FN): 실제 True인 정답을 False라고 예측(오답)
- True Negative(TN): 실제 False인 정답을 False라고 예측(정답)

**정밀도**란 모델이 True라고 분류한 것 중 실제 True의 비율이다.

$$  정밀도 = {TP \over TP + FP}  $$

**재현율**이란 실제 True 중 모델이 True라고 예측한 비율이다.

$$  재현율 = {TP \over TP + FN}  $$

**정확도(Accuracy)**는 우리에게 가장 익숙한 지표로 전체 데이터에서 정답을 맞춘 비율이다.

$$  정확도 = {TP + TN \over TP + FN + FP + TN}  $$

정밀도와 재현율은 모두 실제 True를 True라고 예측한 TP에 초점을 둔 개념이다. 정확도는 익히 사용되는데 성능을 측정하기에 적절하지 않을 때가 있다. 예를 들어 우천을 예측하는 모델을 만들었다고 하자. 100일동안 총 3일 비가왔는데, 모델은 100일 내내 맑았다고 예측했다. 이런 경우에는 100번 중 97번을 정답을 맞췄기에 정확도는 97%이지만 정작 하나도 못 맞춘 셈이다. 이렇게 더 중요한 데이터가 적은 비율을 차지하는 경우 정확도는 좋은 측정 지표가 될 수 없다.

### 과적합(Overfitting)과 과소적합(Underfitting)

머신러닝의 학습과정은 보통 주어진 학습 데이터를 여러번 반복학습하며 점차 성능을 향상시켜 나가는 방식이다. 학습 데이터를 반복하는 횟수를 에포크(epoch)라고 하며 학습 데이터를 한번씩 모두 학습할 때마다 1 epoch이다. 또한 에포크는 사용자가 직접 설정하기에 하이퍼 파라미터에 속한다.

학습을 진행하면 학습 데이터에 대한 성능은 높아질 수 밖에 없다. 하지만 머신러닝의 목적은 결국 모델을 학습시키고 새로운 데이터에 대하여 좋은 성능을 내는 것인데 학습 데이터를 과하게 학습하면 학습 데이터에 대한 성능은 높고, 새로운 데이터에 대한 실제 성능은 떨어지게 된다. 이러한 현상을 **과적합**이라고 하는데 과적합이 발생한 모델은 실제 서비스가 좋지 않기 때문에 결코 좋은 모델이라고 할 수 없다.

반면에 성능이 더욱 올라갈 여지가 있음에도 훈련을 덜 한 상태를 **과소적합**이라고 한다. 보통은 에포크가 적게 설정되어 훈련이 부족한 상태일 때 발생하며, 과적합과 다르게 훈현 데이터에 대한 성능도 좋지 않다.

과적합과 과소적합같은 이름이 주어지게 된 이유는 머신 러닝에서 학습 또는 훈련을 하는 과정을 **적합(fitting)**이라고 하기 때문이다. 과적합을 막을 수 있는 방법으로는 드롭 아웃(Dropout), 조기 종료(Early Stopping) 등이 있고 이 내용은 추후에 다룰 예정이다.

이러한 과적합과 과소적합같은 문제를 방지하기 위하여 테스트 데이터를 분리하여 사용하곤한다. 한 테스트 데이터는 과적합 모니터링과 하이퍼 파라미터 튜닝, 다른 테스트 데이터를 모델의 성능 평가를 위해 사용한다. 그리고 전자의 테스트 데이터를 앞서 언급한 검증 데이터라고 부른다.

과적합을 막기 위해 훈련 데이터의 1 epoch 학습 마다 검증 데이터로 정확도와 오차를 계산하고, 만약 오차가 이전보다 증가한다면 학습을 종료하고 테스트 데이터로 모델을 평가하는 방법이 있다. 이 방식을 조기 종료라고 한다.



머신 러닝의 내용이 너무 많아 포스트를 두 개로 분류하려고 한다. 다음 포스트에서는 머신 러닝의 회귀와 분류에서 대표적인 개념을 알아볼 것이다. 